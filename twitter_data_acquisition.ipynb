{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_data_acquisition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN49E8q_FWHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "e8660a07-75a5-49ba-a638-8728d78687d3"
      },
      "source": [
        "# Library installation on Colab\n",
        "# !pip install GetOldTweets3\n",
        "# !pip install unshortenit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GetOldTweets3\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
            "Collecting pyquery>=1.2.10\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
            "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.1\n",
            "Collecting unshortenit\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/e5/07c5281552f49167229e8c0c21b34353c68235843e53874f09e81a23d269/unshortenit-0.4.0.tar.gz\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from unshortenit) (2.23.0)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.6/dist-packages (from unshortenit) (7.1.2)\n",
            "Requirement already satisfied: lxml>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from unshortenit) (4.2.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->unshortenit) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->unshortenit) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->unshortenit) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->unshortenit) (2.10)\n",
            "Building wheels for collected packages: unshortenit\n",
            "  Building wheel for unshortenit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unshortenit: filename=unshortenit-0.4.0-cp36-none-any.whl size=12392 sha256=3390da666cbbbef2c596b60cc6d8603ad0e4d58f10c79a2091ad3eebf7026f90\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/36/54/345eb1cfb6c1868692a8f57cc4bac140344074e8da6d6b214c\n",
            "Successfully built unshortenit\n",
            "Installing collected packages: unshortenit\n",
            "Successfully installed unshortenit-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QDF65m5FuMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import GetOldTweets3 as got\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import unshortenit"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSnYWrVbfuJj",
        "colab_type": "text"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y4_UbczT-SO",
        "colab_type": "text"
      },
      "source": [
        "### Define function that returns a dataframe of top tweets of a keyword over a specified time period\n",
        "\n",
        "> **Self_nested function in the *except* statement**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q70Xt4XLZMBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retrieveTweets(keyword, year, startDate, endDate, maxTweets):\n",
        "  querySearch = keyword\n",
        "  y = str(year)\n",
        "  start_date = y+'-'+startDate\n",
        "  end_date = y+'-'+endDate\n",
        "  max_tweets = maxTweets\n",
        "  \n",
        "  tic = time.perf_counter()\n",
        "  tweetCriteria = got.manager.TweetCriteria().setQuerySearch(querySearch)\\\n",
        "                                            .setSince(start_date)\\\n",
        "                                            .setUntil(end_date)\\\n",
        "                                            .setTopTweets(True)\\\n",
        "                                            .setMaxTweets(max_tweets)\n",
        "\n",
        "  tweets_df = pd.DataFrame()\n",
        "  try:\n",
        "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "    toc = time.perf_counter()\n",
        "    print(tweets[0].text, tweets[0].favorites, tweets[0].date)\n",
        "    print('retrieving top tweets on {} took {:0.4f} seconds'.format(startDate, toc-tic))\n",
        "    tweets_content = [[tweet.date, tweet.favorites, tweet.text, tweet.retweets] for tweet in tweets]\n",
        "    tweets_df = pd.DataFrame(tweets_content, columns = ['Datetime', 'Favorites', 'Text', 'Retweets'])\n",
        "  except:\n",
        "    print('+'*30+'\\nFAILED TO RETRIEVE TWEETS ON {}, wait 10 minutes. \\n'.format(startDate)+'+'*30)\n",
        "    time.sleep(600)\n",
        "    tweets_df = retrieveTweets(keyword, year, startDate, endDate, maxTweets)\n",
        "\n",
        "  return tweets_df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ULcI9v4UIDR",
        "colab_type": "text"
      },
      "source": [
        "### Define function that returns the url(s) from a tweet\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyKJqGOUgin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findUrl(string): \n",
        "  regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
        "\n",
        "  result = re.findall(regex,string)\n",
        "  urls = []\n",
        "  for i in result:\n",
        "    if i[0].endswith(','):\n",
        "      urls.append(i[0][:-1])\n",
        "    else:\n",
        "      urls.append(i[0])\n",
        "           \n",
        "  return urls"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8lnNtosU3Vv",
        "colab_type": "text"
      },
      "source": [
        "### Define function that returns the list of urls extracted from an array of tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur4aIrTrXvm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractUrl(tweets, url_summary):\n",
        "  from unshortenit import UnshortenIt\n",
        "  # initialze the unshortener\n",
        "  unshortener = UnshortenIt(default_timeout=30)\n",
        "  url_list = []\n",
        "  for i in range(len(tweets)):\n",
        "      \n",
        "    if(i%2000 == 0):\n",
        "      print('This is the {}th link'.format(i))\n",
        "\n",
        "    text = (tweets.loc[i,'Text'])\n",
        "    urls = findUrl(text)\n",
        "\n",
        "    if(urls != []):\n",
        "      for l in urls:\n",
        "        # unshorten all the links\n",
        "        try:\n",
        "          l = unshortener.unshorten(l, force=True, unshorten_nested=True)\n",
        "        except:\n",
        "          continue\n",
        "      \n",
        "        datetime = tweets.loc[i,'Datetime']\n",
        "        favs = tweets.loc[i,'Favorites']\n",
        "        retweets = tweets.loc[i, 'Retweets'] \n",
        "        default = {'Datetime': datetime, 'Favs': favs, 'Retweets': retweets, 'Count': 1}\n",
        "            \n",
        "        if(l in url_summary):\n",
        "          url_summary[l]['Favs'] += favs\n",
        "          url_summary[l]['Retweets'] += retweets\n",
        "          url_summary[l]['Count'] += 1\n",
        "        else:\n",
        "          url_summary[l] = default          \n",
        "          url_list.append(l)\n",
        "  return url_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nx5ooHYX07n",
        "colab_type": "text"
      },
      "source": [
        "### Define function that returns the list of urls that have been filtered"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTkRnU-KX0aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filterUrl(url_summary, url_list):\n",
        "  for i in range(len(url_list)-1, -1, -1):\n",
        "    \n",
        "    if(i%2000 == 0):\n",
        "      print('This is the {}th link'.format(i))\n",
        "\n",
        "    link = url_list[i]\n",
        "    if('pic.twitter.com' in link or 'www.instagram.com' in link or 'www.facebook.com' in link \n",
        "        or 'SoundCloud.com' in link or 'twitter.com' in link or 'www.amazon.com' in link \n",
        "        or 'rddt.co' in link or 'youtu' in link or 'witch.tv' in link or \"tweet.photo\" in link \n",
        "        or 'vimeo.com' in link):\n",
        "      url_list.remove(link)\n",
        "      url_summary.pop(link)\n",
        "      # print('removed link: ' + link)\n",
        "  return url_list"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-LdnWrafgqd",
        "colab_type": "text"
      },
      "source": [
        "# **Execution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uCRfZJDlYYk",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtJGwoY8k6mT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "245aa33e-39ea-40a5-8fa3-fe52c08cdfba"
      },
      "source": [
        "dates = ['05-25','05-26','05-27','05-28','05-29','05-30','05-31','06-01','06-02','06-03','06-04','06-05','06-06','06-07',\n",
        "         '06-08','06-09','06-10','06-11','06-12','06-13','06-14','06-15','06-16','06-17','06-18','06-19','06-20','06-21',\n",
        "         '06-22','06-23','06-24','06-25','06-26','06-27','06-28','06-29','06-30','07-01','07-02','07-03','07-04','07-05',\n",
        "         '07-06','07-07','07-08','07-09','07-10','07-11','07-12','07-13','07-14','07-15','07-16','07-17','07-18','07-19',\n",
        "         '07-20','07-21','07-22','07-23','07-24','07-25','07-26','07-27']\n",
        "         \n",
        "keyword = '#blacklivesmatter'\n",
        "year = 2020\n",
        "maxTweets = 10000\n",
        "\n",
        "tweets_by_date = dict()\n",
        "\n",
        "for i in range(len(dates)-1):\n",
        "  tweets = retrieveTweets(keyword, year, dates[i], dates[i+1], maxTweets)\n",
        "  if(not tweets.empty):\n",
        "    tweets_by_date[dates[i]] = tweets\n",
        "  time.sleep(120)\n",
        "  \n",
        "  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A terribly sad day to be Amy Cooper Head of Insurance Investment Solutions at Franklin Templeton (@FTI_US) in NYC. Franklin Templeton Investments (212) 632-3000 280 Park Ave, New York, NY 10017 Do what you gotta do. #BlackLivesMatter #WhiteLies #WhiteTears 7883 2020-05-25 22:57:52+00:00\n",
            "retrieving top tweets on 05-25 took 2.0491 seconds\n",
            "George Floyd. Say his name. Remember his name. Remember his face. Share this image courtesy of @andresitoguzma. #justiceforfloyd #blacklivesmatter  192 2020-05-26 23:51:52+00:00\n",
            "retrieving top tweets on 05-26 took 9.7667 seconds\n",
            "and for all the people that are pulling the “I’m not interested in politics” card are just so heartless...black people deserve to be PROTECTED & HEARD #BlackLivesMatter 39 2020-05-27 23:59:57+00:00\n",
            "retrieving top tweets on 05-27 took 62.4860 seconds\n",
            "How do we get rid of Abusive Police Officers? It’s obvious they don’t care about cameras #BlackLivesMatter #NAACP 71 2020-05-28 23:59:55+00:00\n",
            "retrieving top tweets on 05-28 took 306.0683 seconds\n",
            "my city #BlackLivesMatter  63 2020-05-29 23:59:57+00:00\n",
            "retrieving top tweets on 05-29 took 213.2037 seconds\n",
            "My prayers from across the ocean. Please stay strong and if you are not familiar with all these horrible events going on right now, please PLEASE read and share this. It’s crazy how such simple things are still not normal in 2020. #JusticeForGeorgeFloyd #BlackLivesMatter 254 2020-05-30 23:59:46+00:00\n",
            "retrieving top tweets on 05-30 took 172.7707 seconds\n",
            "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
            "Try to open in browser: https://twitter.com/search?q=%23blacklivesmatter%20since%3A2020-05-31%20until%3A2020-06-01&src=typd\n",
            "++++++++++++++++++++++++++++++\n",
            "FAILED TO RETRIEVE TWEETS ON 05-31, wait 10 minutes. \n",
            "++++++++++++++++++++++++++++++\n",
            "'if you're white and you're going to a #BlackLivesMatter protest, make sure you stand in the front.' @jeffwittek  299 2020-05-31 23:59:43+00:00\n",
            "retrieving top tweets on 05-31 took 240.2507 seconds\n",
            "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
            "Try to open in browser: https://twitter.com/search?q=%23blacklivesmatter%20since%3A2020-06-01%20until%3A2020-06-02&src=typd\n",
            "++++++++++++++++++++++++++++++\n",
            "FAILED TO RETRIEVE TWEETS ON 06-01, wait 10 minutes. \n",
            "++++++++++++++++++++++++++++++\n",
            "October 17, 2018 Officer Steve Casanova murdered 18yo #CharlesRoundtree HERE IN SAN ANTONIO TEXAS, this happens here in our city as well. So to tell me why does it matter if #GeorgeFloyd died what’s it have to do with us? Because it happens here too! #BlackLivesMatter  79 2020-06-01 23:59:44+00:00\n",
            "retrieving top tweets on 06-01 took 261.7435 seconds\n",
            "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
            "Try to open in browser: https://twitter.com/search?q=%23blacklivesmatter%20since%3A2020-06-02%20until%3A2020-06-03&src=typd\n",
            "++++++++++++++++++++++++++++++\n",
            "FAILED TO RETRIEVE TWEETS ON 06-02, wait 10 minutes. \n",
            "++++++++++++++++++++++++++++++\n",
            "Thanks to you all, we raised $340 for #BlackLivesMatter Thanks so much for donating, sharing, and all around being active in this scary time, Take care you guys.  121 2020-06-02 23:59:36+00:00\n",
            "retrieving top tweets on 06-02 took 312.0520 seconds\n",
            "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
            "Try to open in browser: https://twitter.com/search?q=%23blacklivesmatter%20since%3A2020-06-03%20until%3A2020-06-04&src=typd\n",
            "++++++++++++++++++++++++++++++\n",
            "FAILED TO RETRIEVE TWEETS ON 06-03, wait 10 minutes. \n",
            "++++++++++++++++++++++++++++++\n",
            "Right now outside @NYCMayor’s mansion. The silence is truly deafening. #BlackLivesMatter  469 2020-06-03 23:59:59+00:00\n",
            "retrieving top tweets on 06-03 took 162.8720 seconds\n",
            "Pam is using every ounce of energy she has to raise funds for #blacklivesmatter Let’s hop into her stream and send support and donations!  544 2020-06-04 23:59:56+00:00\n",
            "retrieving top tweets on 06-04 took 172.0238 seconds\n",
            "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
            "Try to open in browser: https://twitter.com/search?q=%23blacklivesmatter%20since%3A2020-06-05%20until%3A2020-06-06&src=typd\n",
            "++++++++++++++++++++++++++++++\n",
            "FAILED TO RETRIEVE TWEETS ON 06-05, wait 10 minutes. \n",
            "++++++++++++++++++++++++++++++\n",
            "Since we all know the #NFL apology is hollow bulls***, I’m wondering, what should the NFL do that would actually look like restitution for all the damage they’ve done, not just to Kap but to racial justice? #Blacklivesmatter #BLM 99 2020-06-05 23:59:48+00:00\n",
            "retrieving top tweets on 06-05 took 125.5102 seconds\n",
            "I need more white people with this energy instead of posting black squares. #BlackLivesMatter  68 2020-06-06 23:59:33+00:00\n",
            "retrieving top tweets on 06-06 took 108.1789 seconds\n",
            "The Earth is moving: Minneapolis City Council members announce intent to disband the city's police department #BlackLivesMatter #GeorgeFloyd 126 2020-06-07 23:59:15+00:00\n",
            "retrieving top tweets on 06-07 took 83.2341 seconds\n",
            "We are just getting started... #Repeal50A #BlackLivesMatter  54 2020-06-08 23:59:05+00:00\n",
            "retrieving top tweets on 06-08 took 82.2767 seconds\n",
            "A flag for the Capitol Hill Autonomous Zone if it forms any kind of a coherent body to govern and negotiate with the Seattle city council for a redress of grievances. #seattleprotest #BlackLivesMatter #NoJusticeNoPeace 77 2020-06-09 23:59:42+00:00\n",
            "retrieving top tweets on 06-09 took 48.2508 seconds\n",
            "Just a reminder: Stay the course #BlackLivesMatter  131 2020-06-10 23:59:45+00:00\n",
            "retrieving top tweets on 06-10 took 47.3523 seconds\n",
            "I guarantee @NASCAR will be stronger for their stance against racism. The people who are “leaving forever” because of the ban of the confederate flag can leave. But I also pray someday those same people will truly understand the why and change their hearts. #BlackLivesMatter 274 2020-06-11 23:58:13+00:00\n",
            "retrieving top tweets on 06-11 took 42.9977 seconds\n",
            "Beginning of this week, I and other marginalized authors let people see how low our advances are, and end of this week lots of people decided the takeaway was \"let's make sure they get even less!\" Fuck it. #DefundPolice, #BlackLivesMatter, time for some Brownstone Punch. 4805 2020-06-12 23:59:05+00:00\n",
            "retrieving top tweets on 06-12 took 42.8198 seconds\n",
            "Meridian Hill/Malcolm X Park filling with #blacklivesmatter protestors. Peaceful, spirited and joyous atmosphere! @PoPville @DCist @washingtonian @washingtonpost @HuffPost @ABC7News @nbcwashington @wusa9 @fox5dc 123 2020-06-13 23:56:46+00:00\n",
            "retrieving top tweets on 06-13 took 43.3151 seconds\n",
            "8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds 8 minutes 46 seconds #BlackLivesMatter 70 2020-06-14 23:59:46+00:00\n",
            "retrieving top tweets on 06-14 took 41.0069 seconds\n",
            "“Negroes are raging all over the place in their country. Should we get involved?” Russian state TV host. According to data, Russian intelligence operatives are attempting to incite violence by white supremacist groups. #blacklivesmatter  10391 2020-06-15 23:59:43+00:00\n",
            "retrieving top tweets on 06-15 took 35.4954 seconds\n",
            "Who wants to help me hit 6,000 followers? I’m. So. Close. #BlackLivesMatter 65 2020-06-16 23:59:35+00:00\n",
            "retrieving top tweets on 06-16 took 27.1311 seconds\n",
            "There is no place in this world for racism. If you hate or discriminate against someone based on the colour of their skin, we are not the same. There needs to be change. #BlackLivesMatter 97 2020-06-17 23:56:43+00:00\n",
            "retrieving top tweets on 06-17 took 27.5656 seconds\n",
            "There are 3.6 million black children living in poverty. Never forget that democrats choose illegal aliens over black lives. #BlackLivesMatter 4116 2020-06-18 23:55:46+00:00\n",
            "retrieving top tweets on 06-18 took 30.9915 seconds\n",
            "#BlackLivesMatter Juneteenth  128 2020-06-19 23:59:49+00:00\n",
            "retrieving top tweets on 06-19 took 34.5641 seconds\n",
            "8 minutes & 46 seconds #BlackLivesMatter  1138 2020-06-20 23:58:14+00:00\n",
            "retrieving top tweets on 06-20 took 24.6205 seconds\n",
            "Oh boy... I can hear the screams at 1600 #BlackLivesMatter Plaza...https://www.axios.com/john-bolton-biden-trump-b216371a-5134-4d09-96af-76ad0fd74cca.html?utm_campaign=organic&amp;utm_medium=socialshare&amp;utm_source=twitter #Bolton #Trump #Biden 144 2020-06-21 23:52:08+00:00\n",
            "retrieving top tweets on 06-21 took 20.2526 seconds\n",
            "Just watched @NASCAR for the first time in my life to see @BubbaWallace . It was an amazing finish, #BubbaWallace best #Talladega ever, and I might be a new fan. They got folks wearing #BlackLivesMatter shirts at a NASCAR race... Wow  1589 2020-06-22 23:59:22+00:00\n",
            "retrieving top tweets on 06-22 took 21.3602 seconds\n",
            "This #BlackLivesMatter #Protest (awesome) 436 2020-06-23 23:56:39+00:00\n",
            "retrieving top tweets on 06-23 took 22.5179 seconds\n",
            "Meet @byDVNLLN! He's a photographer from West Baltimore whose work has found the spotlight as he covered the protests over the death of Freddie Gray and has continued to photograph the #blacklivesmatter movement. Join us Friday to hear Devin at #CMLOU → https://buff.ly/2AY2YSm 22 2020-06-24 23:57:04+00:00\n",
            "retrieving top tweets on 06-24 took 18.1229 seconds\n",
            "What does #BlackLivesMatter care about most? 253 2020-06-25 23:59:46+00:00\n",
            "retrieving top tweets on 06-25 took 21.1537 seconds\n",
            "About Black Lives #DrewComments #KamalaHarris #GeorgeFloyd #BreonnaTaylor #DavidMcAtee #AhmaudArbery #RayshardBrooks #BlackLivesMatter  110 2020-06-26 23:59:53+00:00\n",
            "retrieving top tweets on 06-26 took 16.0581 seconds\n",
            "“breonna taylor was a criminal” “george floyd resisted arrest” stop. unnecessary, excessive force leading to black people dying at the hands of cops is not & will never be justified. please educate yourself on why #BlackLivesMatter goes far beyond police brutality. 602 2020-06-27 23:51:06+00:00\n",
            "retrieving top tweets on 06-27 took 14.9725 seconds\n",
            "That only took 100+ years to long. 1 more symbol of hate getting dealt with, many thousands to go. #BlackLivesMatter  70 2020-06-28 23:54:31+00:00\n",
            "retrieving top tweets on 06-28 took 13.5832 seconds\n",
            "We have not seen ANY outbreaks tied to protests. This includes the re-opening protests (want to get a hair cut) and the #BlackLivesMatter protests (want to not die). We have seen them tied to bars, restaurants, house parties, offices, social clubs and other related activities. 1064 2020-06-29 23:59:58+00:00\n",
            "retrieving top tweets on 06-29 took 15.6717 seconds\n",
            "White #BlackLivesMatter protester attacks black man tearing down BLM banners 2020...  1411 2020-06-30 23:46:45+00:00\n",
            "retrieving top tweets on 06-30 took 16.5290 seconds\n",
            "#BlackLivesMatter because of God, nor because some Marxist organization said so  205 2020-07-01 23:58:15+00:00\n",
            "retrieving top tweets on 07-01 took 15.0530 seconds\n",
            "Are you following @EmmettTill? Goal for today: 30,500 followers of @EmmettTill. Currently at 30,300 followers. If not you, whom If not now, when Please retweet if you already follow @EmmettTill, The Emmett Till Legacy Foundation #JusticeForEmmettTill #BlackLivesMatter 49 2020-07-02 23:55:48+00:00\n",
            "retrieving top tweets on 07-02 took 14.3745 seconds\n",
            "Good cops don't do this. RIP #ElijahMcClain #BlackLivesMatter #abolishthepolice #DefundThePolice 181 2020-07-03 23:57:25+00:00\n",
            "retrieving top tweets on 07-03 took 12.5713 seconds\n",
            "This woman deserves a Nobel Peace Prize for her brave spirit #BlackLivesMatter  4652 2020-07-04 23:55:18+00:00\n",
            "retrieving top tweets on 07-04 took 13.5541 seconds\n",
            "What they did to this baby is just wrong: http://bit.ly/38sEdK6 #BlackLivesMatter #JourneiBrockman 174 2020-07-05 23:55:14+00:00\n",
            "retrieving top tweets on 07-05 took 14.8549 seconds\n",
            "A local #BlackLivesMatter protest. How many black people do you see in the crowd? Maybe 4? 5? It’s a trendy movement for white hipsters. When they’ve moved on, Black people will still be dealing with crumbling communities, fatherlessness, and gang violence.  2278 2020-07-06 23:59:55+00:00\n",
            "retrieving top tweets on 07-06 took 12.9826 seconds\n",
            "Why are whites just expected to take the vile racism coming from #BlackLivesMatter? White Americans should have some guts and stop spending their money at any business that supports BLM. Let them feel 75+% of the population cutting them off. 1153 2020-07-07 23:56:29+00:00\n",
            "retrieving top tweets on 07-07 took 11.8493 seconds\n",
            "Will be sitting in with @TuckerCarlson on @FoxNews to discuss #BlackLivesMatter and their war against the police and our country. Please tune in. 1674 2020-07-08 23:53:12+00:00\n",
            "retrieving top tweets on 07-08 took 12.4143 seconds\n",
            "Did you know Martin Luther King Jr. delivered his I Have a Dream speech eight years to the day after @EmmettTill’s brutal murder on August 28, 1955? Retweet if you follow @EmmettTill #JusticeForEmmettTill #BlackLivesMatter 64 2020-07-09 23:59:59+00:00\n",
            "retrieving top tweets on 07-09 took 12.6516 seconds\n",
            "Democrats released violent convicted felons from prison to vote and under the excuse of Covid BS, they looked the other way when antifa and #BlackLivesMatter rioted and looted We can get one of our own innocents back Thank you President @realDonaldTrump #RogerStone 21 2020-07-10 23:59:26+00:00\n",
            "retrieving top tweets on 07-10 took 10.7111 seconds\n",
            "Hundreds of Jewish synagogues, organizations, & rabbis across the country signed this letter saying #BlackLivesMatter. When you attack Black movements, it leads to more violence against Black people, including Black Jews. Shame on you, @KLoeffler. 99 2020-07-11 23:47:50+00:00\n",
            "retrieving top tweets on 07-11 took 8.0056 seconds\n",
            "Police just tasered this protester in Bay Ridge Brooklyn #BlackLivesMatter desk@scootercaster.com for licensing pic.twitter.com/Zg5DwWlnag 7086 2020-07-12 23:58:57+00:00\n",
            "retrieving top tweets on 07-12 took 9.2552 seconds\n",
            "His wife already wasted 850 million by mismanaging money that was supposed to go to mental health and to the black community. There needs to be an investigation done. #deBlasioMustGo #BlackLivesMatter 857 2020-07-13 23:58:26+00:00\n",
            "retrieving top tweets on 07-13 took 10.1942 seconds\n",
            "Protestors occupy the street outside of the New York Public Library on W 42nd St. #NYCProtest #Blacklivesmatter  97 2020-07-14 23:55:30+00:00\n",
            "retrieving top tweets on 07-14 took 9.9450 seconds\n",
            "I’m here for the third night of the Reclamation Revival here in #RVA. Protesters have occupied the intersection of North Belvidere and West Clay streets but the group is getting ready to march now. Stay tuned for more updates from #BlackLivesMatter protests tonight.  330 2020-07-15 23:58:52+00:00\n",
            "retrieving top tweets on 07-15 took 9.9986 seconds\n",
            "The Black Student-Athlete Council and #GatorsSAAC continue to shape action. #BlackLivesMatter  375 2020-07-16 23:59:58+00:00\n",
            "retrieving top tweets on 07-16 took 10.0825 seconds\n",
            "3 hours after #BlackLivesMatter #BLM mural at #TrumpTower was vandalized, the mural is being repainted by DOT crews. 139 2020-07-17 23:58:18+00:00\n",
            "retrieving top tweets on 07-17 took 10.1382 seconds\n",
            "#CCP_is_terrorist connection to #BlackLivesMatter and #Antifa was known by #Patriots before #PresidentTrump was elected. US Citizens defend the #USConstitution and #DeclarationOfIndependence @CBP @GordonGChang @SolomonYue @desertfox61I @GOPLeader @FreeSpeechHK 584 2020-07-18 23:55:17+00:00\n",
            "retrieving top tweets on 07-18 took 9.8238 seconds\n",
            "Some wholesome images from today's #DenverProtest against the fascists \"Law Enforcement Appreciation Day\" rally which got SHUT THE FUCK DOWN #denverprotests #blacklivesmatter pic.twitter.com/2HpQMKDHM4 141 2020-07-19 23:40:36+00:00\n",
            "retrieving top tweets on 07-19 took 8.2053 seconds\n",
            " Let's help amplify their voices. #GarifunaLivesMatter #BlackLivesMatter  166 2020-07-20 23:40:55+00:00\n",
            "retrieving top tweets on 07-20 took 11.7872 seconds\n",
            "Many mainstream journalists don’t cover #Antifa or #BlackLivesMatter rioters. They cover up for them. They’re not real journalists. The real ones are the brave independents who take risks and show us what’s going on. Hang in there, guys! 11920 2020-07-21 23:22:27+00:00\n",
            "retrieving top tweets on 07-21 took 10.5609 seconds\n",
            "My very old friend and colleague Maureen Healy--a fellow historian and Chair of History at Lewis and Clark College in Portland--was shot above her eye by Trump's federal officers last night in #Portland. Please take a moment to read her statement. #BlackLivesMatter #Vote 6259 2020-07-22 23:12:24+00:00\n",
            "retrieving top tweets on 07-22 took 9.7015 seconds\n",
            "#BlackLivesMatter - ‘Skate for Solidarity’ Salt Lake City, Utah. 6.11.2020  77 2020-07-23 23:33:04+00:00\n",
            "retrieving top tweets on 07-23 took 10.1619 seconds\n",
            "Ohio man in custody after kneeling on crying White child's neck, praising #BlackLivesMatter terrorists. These savages want you dead. They want your family dead. They want your children dead. https://fxn.ws/2OPwOLV #FoxNews 664 2020-07-24 23:51:27+00:00\n",
            "retrieving top tweets on 07-24 took 9.7987 seconds\n",
            "#BLACKLIVESMATTER STILL  8049 2020-07-25 23:29:23+00:00\n",
            "retrieving top tweets on 07-25 took 10.5155 seconds\n",
            "#BlackLivesMatter in Fairfield, CA.  39 2020-07-26 23:45:11+00:00\n",
            "retrieving top tweets on 07-26 took 10.2371 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AImhxoTSjzu8",
        "colab_type": "text"
      },
      "source": [
        "### Combine all tweets together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb_VEtpfj5wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tweets = pd.DataFrame(columns=['Datetime', 'Favorites', 'Text', 'Retweets'])    ## initialize the tweets dataframe for all the retrieved tweets\n",
        "\n",
        "for i in dates:\n",
        "  all_tweets = all_tweets.append(tweets_by_date.get(i))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6pSF64Ab0-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fed9772-c1a3-4e31-b7ec-14627ef6bf9e"
      },
      "source": [
        "# Verify raw data\n",
        "print(len(all_tweets))\n",
        "# all_tweets\n",
        "# print([tweets_by_date[x].shape for x in tweets_by_date])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsrurzP1hxIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Save all_tweets if a BACKUP is needed\n",
        "# all_tweets.to_csv('blacklivesmatter_05-25_07-26_allTweets_v2.csv')\n",
        "# all_tweets = pd.read_csv('/content/blacklivesmatter_05-25_07-26_allTweets_v2.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs0VAJ5qkWuP",
        "colab_type": "text"
      },
      "source": [
        "### Process tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHm59CgkJfo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## There is no need to reverse the order of all_tweets, unlike the first verison,\n",
        "## because it is already in the desired order (from earliest to latest)\n",
        "\n",
        "# Initialize variables for processing raw data\n",
        "all_url_list = [] # ordered from earliest to lastest\n",
        "url_summary = dict() # format --> 'link': {info}   | {info} format --> {'Datetime', 'Favorites', 'Retweets', 'Count'}\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcwtndEZX0sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "fe0e235c-9ba9-4233-b78a-e000f7e733e7"
      },
      "source": [
        "# Processing\n",
        "all_url_list = extractUrl(all_tweets, url_summary) # extract all urls without before filtering"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the 0th link\n",
            "This is the 2000th link\n",
            "This is the 4000th link\n",
            "This is the 6000th link\n",
            "This is the 8000th link\n",
            "This is the 10000th link\n",
            "This is the 12000th link\n",
            "This is the 14000th link\n",
            "This is the 16000th link\n",
            "This is the 18000th link\n",
            "This is the 20000th link\n",
            "This is the 22000th link\n",
            "This is the 24000th link\n",
            "This is the 26000th link\n",
            "This is the 28000th link\n",
            "This is the 30000th link\n",
            "This is the 32000th link\n",
            "This is the 34000th link\n",
            "This is the 36000th link\n",
            "This is the 38000th link\n",
            "This is the 40000th link\n",
            "This is the 42000th link\n",
            "This is the 44000th link\n",
            "This is the 46000th link\n",
            "This is the 48000th link\n",
            "This is the 50000th link\n",
            "This is the 52000th link\n",
            "This is the 54000th link\n",
            "This is the 56000th link\n",
            "This is the 58000th link\n",
            "This is the 60000th link\n",
            "This is the 62000th link\n",
            "This is the 64000th link\n",
            "This is the 66000th link\n",
            "This is the 68000th link\n",
            "This is the 70000th link\n",
            "This is the 72000th link\n",
            "This is the 74000th link\n",
            "This is the 76000th link\n",
            "This is the 78000th link\n",
            "This is the 80000th link\n",
            "This is the 82000th link\n",
            "This is the 84000th link\n",
            "This is the 86000th link\n",
            "This is the 88000th link\n",
            "This is the 90000th link\n",
            "This is the 92000th link\n",
            "This is the 94000th link\n",
            "This is the 96000th link\n",
            "This is the 98000th link\n",
            "This is the 100000th link\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh0s-rP4Xnjt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f1c7b4d2-2a08-4d32-9a65-c7b827521f82"
      },
      "source": [
        "# Processing\n",
        "all_url_list = filterUrl(url_summary, all_url_list) # remove irrelevant urls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the 4000th link\n",
            "This is the 2000th link\n",
            "This is the 0th link\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1AJe2zmuMOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23b8cc7f-d99e-478c-a155-b341d53fee9f"
      },
      "source": [
        "print(len(all_url_list))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBRACvEum6i9",
        "colab_type": "text"
      },
      "source": [
        "### Generate data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhr2IUohpC9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f2bf821-9e67-4f92-ff22-fca27b3aa5e3"
      },
      "source": [
        "summary_list = []\n",
        "\n",
        "for i in all_url_list:\n",
        "    link = i\n",
        "    datetime = url_summary[i]['Datetime']\n",
        "    favs = url_summary[i]['Favs']\n",
        "    retweets = url_summary[i]['Retweets']\n",
        "    count = url_summary[i]['Count']\n",
        "\n",
        "    summary_list.append([link, datetime, favs, retweets, count])\n",
        "\n",
        "summary_df = pd.DataFrame(summary_list, columns=['Link', 'Datetime', 'Favs', 'Retweets', 'Count'])\n",
        "\n",
        "# check\n",
        "summary_df.head()\n",
        "print(len(summary_df))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BasS24HqtHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_df.to_csv('blacklivesmatter_05-25_07-26_topTweets_urlSummary.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWVOUnJ6gDi4",
        "colab_type": "text"
      },
      "source": [
        "# Tests and experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDQd7lkWF-Ty",
        "colab_type": "text"
      },
      "source": [
        "Set up searching criteria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTuFrZ2ZGFjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "querySearch = '#blacklivesmatter'\n",
        "start_date = '2020-05-25'\n",
        "max_tweets = 10000\n",
        "file_counter = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfWZDvdQGUqW",
        "colab_type": "text"
      },
      "source": [
        "Test - get 10000 tweets by query search\n",
        "\n",
        "--\n",
        "\n",
        "1000 - ~35 seconds \n",
        "\n",
        "10000 - ~10.25 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t99GEmXoGT1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d0a297aa-73f5-4f4d-bccb-d6036aa7fccc"
      },
      "source": [
        "import time\n",
        "# time the excecution time for 1000 tweets\n",
        "tic = time.perf_counter()\n",
        "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(querySearch)\\\n",
        "                                            .setSince('2020-06-03')\\\n",
        "                                            .setUntil('2020-06-04')\\\n",
        "                                            .setTopTweets(True)\\\n",
        "                                            .setMaxTweets(max_tweets)\n",
        "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "toc = time.perf_counter()\n",
        "print(tweets[0].text, tweets[0].favorites, tweets[0].date)\n",
        "print('retrieving top tweets took {:0.4f} seconds'.format(toc-tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Right now outside @NYCMayor’s mansion. The silence is truly deafening. #BlackLivesMatter  474 2020-06-03 23:59:59+00:00\n",
            "retrieving top tweets took 181.0698 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoJI0MZEJ3iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b0db9f8d-150e-4fb1-f07d-53da08d6eaea"
      },
      "source": [
        "print(len(tweets))\n",
        "print(tweets[0].date)\n",
        "print(tweets[-1].date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5397\n",
            "2020-06-03 23:59:59+00:00\n",
            "2020-06-03 00:00:00+00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsA_XqI8KQsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "9de04d5c-7fe9-4e31-92e3-5a751df7433c"
      },
      "source": [
        "tic = time.perf_counter()\n",
        "print(tic)\n",
        "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(querySearch)\\\n",
        "                                            .setSince('2020-06-02')\\\n",
        "                                            .setUntil('2020-06-03')\\\n",
        "                                            .setMaxTweets(1000000)\n",
        "tweets = got.manager.TweetManager.getTweets(tweetCriteria, receiveBuffer=storeBuffer, bufferLength=1000)\n",
        "toc = time.perf_counter()\n",
        "print(tweets[0].text, tweets[0].favorites, tweets[0].date)\n",
        "print('retrieving all tweets on 6/2/2020 took {:0.4f} seconds'.format(toc-tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6713.098831614\n",
            "6743.314410058\n",
            "6783.17699547\n",
            "6822.823443564\n",
            "6863.342974963\n",
            "6903.844389318\n",
            "6944.985780068\n",
            "6986.113742241\n",
            "7025.961669107\n",
            "7066.451637094\n",
            "7107.471227207\n",
            "7147.728528007\n",
            "7188.85939416\n",
            "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
            "Try to open in browser: https://twitter.com/search?q=%23blacklivesmatter%20since%3A2020-06-02%20until%3A2020-06-03&src=typd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KquwUEwMyPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "352cbb94-91be-4bae-ab1f-6190878e5eed"
      },
      "source": [
        "print('number of tweets: ' + str(len(tweets)))\n",
        "print(tweets[0].date)\n",
        "print(tweets[9999].date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of tweets: 10000\n",
            "2020-06-02 23:59:59+00:00\n",
            "2020-06-02 23:35:08+00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ZvFylSY3Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def storeBuffer(resultsAux):\n",
        "  # Creating list of chosen tweet data\n",
        "  text_tweets = [[tweet.date, tweet.favorites, tweet.text] for tweet in resultsAux]\n",
        "\n",
        "  # Creation of dataframe from tweets    \n",
        "  tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Favorites', 'Text'])\n",
        "\n",
        "  # Converting tweets dataframe to csv file\n",
        "  global file_counter\n",
        "  tweets_df.to_csv('blacklivesmatter_06-02_{}k-tweets.csv'.format(file_counter, sep=','))\n",
        "  file_counter += 1\n",
        "\n",
        "  print(time.perf_counter())\n",
        "  time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGrL211zIbAY",
        "colab_type": "text"
      },
      "source": [
        "verify results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjaB9LLHIVgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3a50adc4-faec-4798-c7cc-d00df136167f"
      },
      "source": [
        "querySearch = '#blacklivesmatter'\n",
        "start_date = '2020-06-12'\n",
        "end_date = '2020-06-13'\n",
        "max_tweets = 10000\n",
        "  \n",
        "tic = time.perf_counter()\n",
        "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(querySearch)\\\n",
        "                                            .setSince(start_date)\\\n",
        "                                            .setUntil(end_date)\\\n",
        "                                            .setTopTweets(True)\\\n",
        "                                            .setMaxTweets(max_tweets)\n",
        "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "toc = time.perf_counter()\n",
        "print(tweets[0].text, tweets[0].favorites, tweets[0].date)\n",
        "print('retrieving top tweets on {} took {:0.4f} seconds'.format(dates[i], toc-tic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Who in the USA is concerned about climate change? 49% of Whites 57% of Blacks 70% of Latinx Imagine what would be possible if POC didn’t have to deal with racism and could devote that energy to #ClimateSolutions... @ClimatePower #BlackLivesMatter  1120 2020-06-12 23:57:39+00:00\n",
            "retrieving top tweets on 06-12 took 17.5493 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MraHRnJ0JUES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bde540a1-c596-4c40-8b8a-df5c0dcafffb"
      },
      "source": [
        "print(len(tweets))\n",
        "print(tweets[-1].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "381\n",
            "We knew in Philly that @Starbucks doesn't care about #BLM and they have truly shown it with this stand against people wearing anything that supports #blacklivesmatter #BoycottStarbucks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcXJf5JHn85T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459bbd5e-bdd2-4a6f-aae7-35ac5387f4c7"
      },
      "source": [
        "import datetime\n",
        "x = datetime.datetime.today()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2020, 6, 21, 2, 7, 0, 974210)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}